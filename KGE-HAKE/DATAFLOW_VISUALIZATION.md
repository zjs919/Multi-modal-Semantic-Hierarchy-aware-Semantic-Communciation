# KGE-HAKE 数据流可视化

## 1. 整体数据流图

```
┌─────────────────────────────────────────────────────────────────┐
│                        数据加载阶段                              │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
        ┌─────────────────────────────────────┐
        │      DataReader (data.py)            │
        │  ┌───────────────────────────────┐   │
        │  │ read_dict()                   │   │
        │  │ - entities.dict → entity_dict │   │
        │  │ - relations.dict → rel_dict  │   │
        │  └───────────────────────────────┘   │
        │  ┌───────────────────────────────┐   │
        │  │ read_data()                   │   │
        │  │ - train.txt → train_data      │   │
        │  │ - valid.txt → valid_data      │   │
        │  │ - test.txt → test_data        │   │
        │  │ 格式: (h_id, r_id, t_id)      │   │
        │  └───────────────────────────────┘   │
        └─────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                        训练数据准备阶段                           │
└─────────────────────────────────────────────────────────────────┘
                              │
                ┌─────────────┴─────────────┐
                ▼                           ▼
    ┌──────────────────────┐    ┌──────────────────────┐
    │  TrainDataset        │    │  TestDataset         │
    │  (训练用)            │    │  (评估用)            │
    └──────────────────────┘    └──────────────────────┘
                │                           │
                ▼                           ▼
    ┌──────────────────────┐    ┌──────────────────────┐
    │ two_tuple_count()    │    │ 生成所有候选实体     │
    │ - hr_map: {(h,r):[t]}│    │ - HEAD_BATCH: (?,r,t)│
    │ - tr_map: {(t,r):[h]}│    │ - TAIL_BATCH: (h,r,?)│
    │ - hr_freq/tr_freq    │    │ - filter_bias标记    │
    └──────────────────────┘    └──────────────────────┘
                │                           │
                ▼                           ▼
    ┌──────────────────────┐    ┌──────────────────────┐
    │ __getitem__()        │    │ __getitem__()       │
    │ - 正样本: (h,r,t)     │    │ - 正样本: (h,r,t)   │
    │ - 负采样: 替换h或t   │    │ - 候选: 所有实体    │
    │ - 过滤: 避免正样本   │    │ - 过滤: 已存在三元组│
    │ - 权重: subsampling  │    └──────────────────────┘
    └──────────────────────┘
                │
                ▼
    ┌──────────────────────┐
    │ DataLoader           │
    │ - batch_size         │
    │ - shuffle            │
    │ - collate_fn         │
    └──────────────────────┘
                │
                ▼
    ┌──────────────────────┐
    │ BidirectionalIterator│
    │ - 交替HEAD/TAIL_BATCH│
    └──────────────────────┘
```

## 2. 训练步骤数据流

```
┌─────────────────────────────────────────────────────────────────┐
│                    train_step 数据流                             │
└─────────────────────────────────────────────────────────────────┘

训练迭代器
    │
    ▼
┌─────────────────────────────────────┐
│ 获取批次数据                         │
│ - positive_sample: [B, 3]           │
│ - negative_sample: [B, N]           │
│ - subsampling_weight: [B]             │
│ - batch_type: HEAD_BATCH/TAIL_BATCH  │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ model.forward()                      │
│                                      │
│ 1. 嵌入查找                          │
│    - entity_embedding[positive]     │
│    - relation_embedding[positive]    │
│    - entity_embedding[negative]     │
│                                      │
│ 2. 维度变换                          │
│    HEAD_BATCH:                       │
│    - head: [B, N, D]                 │
│    - rel:  [B, 1, D]                 │
│    - tail: [B, 1, D]                 │
│                                      │
│    TAIL_BATCH:                       │
│    - head: [B, 1, D]                 │
│    - rel:  [B, 1, D]                 │
│    - tail: [B, N, D]                 │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ model.func() (HAKE实现)              │
│                                      │
│ 1. 分离嵌入                          │
│    head → [phase_head, mod_head]     │
│    rel  → [phase_rel, mod_rel, bias]│
│    tail → [phase_tail, mod_tail]     │
│                                      │
│ 2. 相位计算                          │
│    phase_score = sin((h_p+r_p-t_p)/2)│
│                                      │
│ 3. 模长计算                          │
│    r_score = ||h_m*(r_m+b_r)-t_m*...||│
│                                      │
│ 4. 综合得分                          │
│    score = gamma - (phase + r_score) │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 损失计算                             │
│                                      │
│ 1. 正样本得分                        │
│    pos_score = model(pos_sample)     │
│    pos_loss = -log(sigmoid(pos_score))│
│                                      │
│ 2. 负样本得分（自对抗）              │
│    neg_score = model(neg_sample)     │
│    weights = softmax(neg_score * T)  │
│    neg_loss = -sum(weights * log(...))│
│                                      │
│ 3. 加权平均                          │
│    loss = (pos_loss + neg_loss) / 2  │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 反向传播                            │
│ loss.backward()                     │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 参数更新                            │
│ optimizer.step()                    │
└─────────────────────────────────────┘
```

## 3. 评估步骤数据流

```
┌─────────────────────────────────────────────────────────────────┐
│                      test_step 数据流                            │
└─────────────────────────────────────────────────────────────────┘

测试数据集
    │
    ▼
┌─────────────────────────────────────┐
│ TestDataset.__getitem__()            │
│                                      │
│ 对于每个测试三元组 (h, r, t):        │
│                                      │
│ HEAD_BATCH (预测head):               │
│ - positive_sample: (h, r, t)        │
│ - negative_sample: [0, 1, ..., N-1] │
│   (所有实体作为候选)                 │
│ - filter_bias: [0, 0, ..., -1, ...]  │
│   (0: 有效负样本, -1: 需过滤)        │
│                                      │
│ TAIL_BATCH (预测tail):               │
│ - 类似，但预测tail                   │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ model.forward()                      │
│ 计算所有候选的得分                   │
│ score: [B, N] (N=num_entity)        │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 应用过滤                            │
│ score += filter_bias                │
│ (将已存在的三元组得分设为最低)       │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 排序和排名                          │
│ argsort = sort(score, descending)   │
│ ranking = find(positive_arg in argsort)│
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 计算指标                            │
│ - MRR = 1 / ranking                  │
│ - HITS@1 = 1 if ranking <= 1        │
│ - HITS@3 = 1 if ranking <= 3        │
│ - HITS@10 = 1 if ranking <= 10      │
└─────────────────────────────────────┘
```

## 4. HAKE模型嵌入结构

```
实体嵌入 (entity_embedding)
┌─────────────────────────────────────┐
│ [num_entity, hidden_dim * 2]         │
│                                      │
│ ┌──────────────┬──────────────┐    │
│ │ phase部分    │ modulus部分  │    │
│ │ [:, :D]      │ [:, D:]      │    │
│ │ (相位)       │ (模长)       │    │
│ └──────────────┴──────────────┘    │
└─────────────────────────────────────┘

关系嵌入 (relation_embedding)
┌─────────────────────────────────────┐
│ [num_relation, hidden_dim * 3]       │
│                                      │
│ ┌──────────┬──────────┬──────────┐  │
│ │ phase    │ modulus  │ bias     │  │
│ │ [:, :D]  │ [:, D:2D]│ [:, 2D:] │  │
│ └──────────┴──────────┴──────────┘  │
└─────────────────────────────────────┘
```

## 5. 负采样策略详解

```
正样本: (h=5, r=2, t=10)

HEAD_BATCH (替换head，预测 ?)
    │
    ▼
┌─────────────────────────────────────┐
│ 1. 生成候选负样本                    │
│    candidates = [0, 1, 2, ..., N-1]  │
│    (随机采样，数量=neg_size*2)        │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 2. 过滤正样本                        │
│    使用 tr_map[(t=10, r=2)]          │
│    移除所有使得 (?, 2, 10) 为正样本的h│
│    例如: tr_map[(10,2)] = [5, 8, 12] │
│    过滤后: [0, 1, 3, 4, 6, 7, ...]  │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│ 3. 选择neg_size个负样本              │
│    negative_heads = [0, 1, 3, ...]   │
│    最终: [(0,2,10), (1,2,10), ...]   │
└─────────────────────────────────────┘

TAIL_BATCH (替换tail，预测 ?)
    │
    ▼
┌─────────────────────────────────────┐
│ 类似流程，但使用 hr_map[(h=5, r=2)]  │
│ 过滤使得 (5, 2, ?) 为正样本的t        │
└─────────────────────────────────────┘
```

## 6. 子采样权重计算

```
对于三元组 (h, r, t):

subsampling_weight = sqrt(1 / (hr_freq[(h,r)] + tr_freq[(t,r)]))

其中:
- hr_freq[(h,r)]: (h, r) 作为 (h, r, ?) 出现的次数
- tr_freq[(t,r)]: (t, r) 作为 (?, r, t) 出现的次数

目的:
- 降低高频三元组的影响
- 防止模型过度拟合常见模式
- 提高对稀有关系的学习能力

示例:
- 高频: hr_freq=100, tr_freq=100 → weight ≈ 0.071
- 低频: hr_freq=1, tr_freq=1 → weight ≈ 0.707
```

## 7. 自对抗负采样

```
传统负采样:
    loss = -log(sigmoid(pos_score)) - log(sigmoid(-neg_score))

自对抗负采样:
    1. 计算所有负样本的得分
       neg_scores = [s1, s2, ..., sN]
    
    2. 计算权重（温度缩放）
       weights = softmax(neg_scores * temperature)
       # 高得分的负样本（难样本）获得更高权重
    
    3. 加权损失
       neg_loss = -sum(weights * log(sigmoid(-neg_scores)))
    
优势:
    - 自动关注难负样本
    - 提高训练效率
    - 无需手动设计负采样策略
```

## 8. 数据流时序图

```
训练循环时序:

时间轴 →
│
├─ 初始化
│  ├─ DataReader 读取数据
│  ├─ 创建 TrainDataset
│  ├─ 创建 DataLoader
│  └─ 创建 BidirectionalIterator
│
├─ 训练循环 (for step in range(max_steps))
│  │
│  ├─ 获取批次 (next(iterator))
│  │  ├─ 正样本 + 负样本
│  │  └─ 子采样权重
│  │
│  ├─ 前向传播
│  │  ├─ 嵌入查找
│  │  ├─ 维度变换
│  │  └─ 计算得分
│  │
│  ├─ 损失计算
│  │  ├─ 正样本损失
│  │  └─ 负样本损失（自对抗）
│  │
│  ├─ 反向传播
│  │  └─ loss.backward()
│  │
│  ├─ 参数更新
│  │  └─ optimizer.step()
│  │
│  ├─ 定期验证 (每 valid_steps 步)
│  │  ├─ 在验证集上评估
│  │  └─ 计算 MRR, HITS@K
│  │
│  └─ 定期保存 (每 save_checkpoint_steps 步)
│     └─ 保存模型和嵌入
│
└─ 最终评估
   └─ 在测试集上评估
```

## 9. 内存和计算复杂度

```
数据存储:
- entity_embedding: O(N * D)  (N=实体数, D=嵌入维度)
- relation_embedding: O(R * D) (R=关系数)
- hr_map/tr_map: O(T) (T=三元组数，稀疏存储)

训练时内存:
- 批次数据: O(B * N * D) (B=batch_size, N=负样本数)
- 梯度: O(N * D + R * D)
- 总内存: O(B * N * D + N * D + R * D)

计算复杂度:
- 嵌入查找: O(B * N)
- 得分计算: O(B * N * D)
- 反向传播: O(B * N * D)
- 总复杂度: O(B * N * D) per step
```

## 10. 可扩展性数据流

```
联邦学习数据流:

客户端1                   服务器                   客户端2
   │                        │                        │
   ├─ 本地数据1             │                        ├─ 本地数据2
   │                        │                        │
   ├─ 本地训练               │                        ├─ 本地训练
   │  (只更新本地实体)       │                        │  (只更新本地实体)
   │                        │                        │
   ├─ 发送梯度/参数 ────────→│                        ├─ 发送梯度/参数 ────────→│
   │                        │                        │
   │                        ├─ 聚合参数              │
   │                        │  (FedAvg)              │
   │                        │                        │
   │←──── 分发聚合参数 ──────┤                        │←──── 分发聚合参数 ──────┤
   │                        │                        │
   └─ 更新模型               │                        └─ 更新模型
```

